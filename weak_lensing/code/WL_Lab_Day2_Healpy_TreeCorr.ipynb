{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import healpy as hp\n",
    "import treecorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2.1 : Working and plotting data on the celestial sphere with healpy\n",
    "\n",
    "In this exercise you will generate all-sky maps for different NSIDE parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For NSIDE = $2^0$ make an array of size npix with np.arange\n",
    "\n",
    " - Use the equation provided in the lab manual to first compute the number of pixels (npix) for the given NSIDE. \n",
    " - Compare your result the output of hp.nside2npix command \n",
    " \n",
    " The first few functions are already written to help you get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSIDE = ???\n",
    "npix_healpy = hp.nside2npix(nside=NSIDE)\n",
    "print(npix_healpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npix = ??? # write the relevant equation from the manual and compare the value of npix with npix_healpy above\n",
    "print(npix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Use np.arange to create an array of size npix and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_arr = np.arange(npix)\n",
    "print(map_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the array in healpy map format using the function hp.mollview (https://healpy.readthedocs.io/en/latest/generated/healpy.visufunc.mollview.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(map_arr);\n",
    "#The colors in the map represent the values in your array, mapped to HEALPix pixels on the sphere.\n",
    "#For NSIDE = 1 (12 pixels), you will see 12 colored regions, each corresponding to one pixel.\n",
    "#By examining the map, you can deduce which pixel index corresponds to which region (e.g., the first pixel s\n",
    "#tarts near the north pole, left of the meridian).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The pixel with index 0 is typically located near the north pole, and the indices increase as you move southward and around the sphere, following the HEALPix RING ordering by default.\n",
    "\n",
    "#The color gradient (from dark to yellow) helps you visually identify which pixel index is assigned to which region on the sky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For NSIDE = $2^0$, notice the colour scheme of the pixels (from dark to light pixels) --> see how the pixels are arranged. Try to figure out which one is the first and which one is the last pixel. For example: zeroth index starts at the north pole left to the meridian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the $\\theta_{pixel}$ for this NSIDE using hp.nside2pixarea (https://healpy.readthedocs.io/en/latest/generated/healpy.pixelfunc.nside2pixarea.html) and the relevant equation provided in the lab manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to give your answer in degrees and also in arcmins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat all the above exercises for NSIDE = $2^1, 2^2, 2^3, 2^{11}$. Visualize the changes at map level and also compute the number of pixels and pixel scale for the different NSIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#At low NSIDE values, the Mollweide plots clearly show large, distinct regions corresponding to individual pixels. As NSIDE increases, \n",
    "#the pixels become much smaller and the map appears smoother, \n",
    "#illustrating the increased spatial resolution\n",
    "#GÃ³rski et al. (2005), \"HEALPix: A Framework for High-Resolution Discretization\". ApJ 622:759-771\n",
    "# Zonca et al. (2019), \"healpy: equal area pixelization and spherical harmonics transforms\". JOSS 4(35):1298"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For our lab we will be working with NSIDE = $2^{11}$. This is the same resolution as the weak lensing shear maps we will use from the Takahashi (T17) simulations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2.2 : Extracting circular patches on the sphere with healpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will query a circular patch (disc) with a certain radius at a specified position on the NSIDE = $2^{11}$ map that you have created above. In order to do so:\n",
    "\n",
    "- First specify the center of the patch in angular spherical coordinates and the radius of the patch (use 2.5 degrees as the angular radius of the patch). To achieve this, use the function hp.ang2vec(theta, phi) to get the normalised unit vector of the center of the patch at the angular spherical coordinates theta and phi of the patch center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then query a circular disc of desired radius (in radians) using the function hp.query_disc(NSIDE, vec=vec, radius=np.radians(radius_patch)) . This will return all the pixel indices of the above map which fall within the disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now assign a value of 1 to all these disc pixels and visualise the corresponding map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On the map draw 5 separate non-overlapping circular patches (use a loop) and visualize the final map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2.3: Importing and checking the simulated weak lensing shear maps from Takahashi simulations (T17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will import the publicly available Takahashi (T17) simulation weak lensing shear ($\\gamma_1$ and $\\gamma_2$ components) as healpix maps \n",
    "\n",
    "For details about the simulation, refer to: http://cosmo.phys.hirosaki-u.ac.jp/takahasi/allsky_raytracing/). For the lab we will be using the shear maps at 2 different source redshifts at $z_{s,1}$ = 0.5739 and $z_{s,2}$ = 1.0334. The maps are already downloaded in the directory you are working in. We will initially start with only the $z_{s,1}$ map\n",
    "\n",
    "- Load (use hp.read_map) both the $\\gamma_1$ and $\\gamma_2$ components of the shear map at source redshift $z_{s,1}$ and visualize them. Check how many pixels are there in each shear map and verify that it corresponds to NSIDE = $2^{11}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2.4: Working with *treecorr*: package to compute shear two-point correlation functions (2PCFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure the shear 2PCFs $\\xi_{\\pm}$ from the $\\gamma_1$ and $\\gamma_2$ maps at source redshift $z_{s,1}$ you have visualized above you will use the publicly available code package treecorr (https://rmjarvis.github.io/TreeCorr/_build/html/index.html). \n",
    "\n",
    "Treecorr has many functionalities (computing different kinds of 2-point correlations and also 3-point correlations). As we are interested in computing specifically the shear-shear 2PCF we will use the GGCorrelation module. Read  up about it in https://rmjarvis.github.io/TreeCorr/_build/html/gg.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Firstly, treecorr needs access to the shear $\\gamma_1$ and $\\gamma_2$ data in the form of the  values and the associated ra and dec of the shear pixels. Use the pixel indices of one of the circular discs you had extracted in P2.2, compute the ra and dec of those pixels using the function provided below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel2RaDec(pixel_indices, NSIDE):\n",
    "    theta, phi = hp.pixelfunc.pix2ang(NSIDE, pixel_indices, nest=False)\n",
    "    ra = phi\n",
    "    dec = np.pi/2.0-theta\n",
    "    return ra, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print out the gamma1 and gamma2 values of these extracted pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a treecorr catalog (use https://rmjarvis.github.io/TreeCorr/_build/html/catalog.html) which contains the ra, dec, gamma1, gamma2, ra_units and dec_units of those extracted pixels. IMPORTANT: You will also need to set the flip_g1=True in the catalog (due to the convention adopted in the Takhashi simulation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then create a GGCorrelation (https://rmjarvis.github.io/TreeCorr/_build/html/gg.html) instance where you provide the minimum, maximum and the total number of angular separations within which you want to compute the correlations. You'll also need to provide the separation units. Compute the correlations from 5-140 arcmins in 20 bins logarithmically spaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, in order to compute the $\\xi_{\\pm}$ shear 2PCFs, insert the catalog you have created above into the GG instance using the function process()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Call the methods xip and xim of the treecorr GG instance to get the output of the correlation values. Plot them against the angular bins (which you can get from the nominal bin centres, rnom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2.5: Computing the average shear 2PCFs in several patches in the $z_{s,1}$ map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will compute the shear 2PCFs within multiple patches in the $z_{s,1}$ map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Repeat P2.4 for 100 randomly located (preferably non-overlapping) patches on the $z_{s,1}$ map; store the xip and xim computed in 15 bins using treecorr for these 100 patches in a 100x20 array (make separate arrays for xip and xim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the mean and standard deviation of the correlations over all these 100 patches. Use np.mean and np.std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot the individual 100 2PCFs in grey and their mean in red with the standard deviation as the error bars. Use plt.errorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2.6: Computing the average shear 2PCFs in several patches in the $z_{s,2}$ map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will compute the shear 2PCFs within multiple patches in the $z_{s,2}$ map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Repeat P2.5 for the $z_{s,2}$ map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2.7: Comparing theory calculations of the shear 2PCFs against the measurements from the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and plot the theoretical curves for $z_{s,1}$ and $z_{s,2}$ (that you computed on the first day in P1.7) together with the average of the measurements from the Takahashi simulations (that you computed in P2.5 and P2.6). Compare the theoretical curves to your measurements and see whether they agree or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add more coding cells as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "59f7c972767771a2055893ba8d0d8bada60eacffc377d0b05891d67b4661dbba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
